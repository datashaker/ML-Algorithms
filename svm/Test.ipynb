{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svm import SVMTrainer, SVMPredictor\n",
    "from kernel import Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel(object):\n",
    "    \"\"\"Check kernels here https://en.wikipedia.org/wiki/Support_vector_machine\"\"\"\n",
    "    @staticmethod\n",
    "    def linear():\n",
    "        return lambda x, y: np.inner(x, y)\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian(sigma):\n",
    "        return lambda x,y: np.exp(-sigma * np.linalg.norm(x-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt.solvers\n",
    "import logging\n",
    "\n",
    "\n",
    "MIN_SUPPORT_VECTOR_MULTIPLIER = 1e-5\n",
    "\n",
    "\n",
    "class SVMTrainer(object):\n",
    "    def __init__(self, kernel, c=0.1):\n",
    "        self._kernel = kernel\n",
    "        self._c = c\n",
    "\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "            y: vector of labels\n",
    "            next step: Compute lagrange multipliers by calling _compute_lagrange_multipliers method\n",
    "            retrun:    Return Predictor object by calling _create_predictor method\n",
    "        \"\"\"\n",
    "        lagrange_multipliers = self._compute_lagrange_multipliers(X, y)\n",
    "        return self._create_predictor(X, y, lagrange_multipliers)\n",
    "\n",
    "\n",
    "    def _kernel_matrix(self, X):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "            next step: Get number of samples\n",
    "            next step: Create zero matrix of quadratic shape of number of samples \n",
    "            next step: Calculate kernels\n",
    "            retrun:    Return Kernels matrix\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        \n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "\n",
    "        print(X)\n",
    "\n",
    "        for i, x_i in enumerate(X):\n",
    "            for j, x_j in enumerate(X):\n",
    "                K[i, j] = self._kernel(x_i, x_j)\n",
    "\n",
    "        return K\n",
    "        '''\n",
    "        \n",
    "        K = np.zeros((np.shape(y)[0],1))\n",
    "        for i, x_i in range(np.shape(y)[0]):\n",
    "            for j, x_j in range(support_vectors):\n",
    "                K[i, j] = self._kernel(x_i, x_j)\n",
    "\n",
    "        return K\n",
    "        '''\n",
    "\n",
    "\n",
    "    def _create_predictor(self, X, y, lagrange_multipliers):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "            y: vector of labels\n",
    "            lagrange_multipliers: vector of langrange multipliers\n",
    "            next step: Get non-zero lagrange multipliers indicies\n",
    "            next step: Get non-zero lagrange multipliers\n",
    "            next step: Get support vecorts\n",
    "            next step: Get support vecort labels\n",
    "            next step: Ð¡ompute bias (use avg trick)\n",
    "            retrun   : Return SVMPredictor object\n",
    "        \"\"\"\n",
    "\n",
    "        support_vector_indices = lagrange_multipliers > MIN_SUPPORT_VECTOR_MULTIPLIER\n",
    "\n",
    "        support_multipliers = lagrange_multipliers[support_vector_indices]\n",
    "\n",
    "        support_vectors = X[support_vector_indices]\n",
    "\n",
    "        support_vector_labels = y[support_vector_indices]\n",
    "\n",
    "        bias = np.mean(\n",
    "            [y_k - SVMPredictor(\n",
    "                    kernel=self._kernel,\n",
    "                    bias=0.0,\n",
    "                    weights=support_multipliers,\n",
    "                    support_vectors=support_vectors,\n",
    "                    support_vector_labels=support_vector_labels\n",
    "                ).predict(x_k) for (y_k, x_k) in zip(support_vector_labels, support_vectors)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return SVMPredictor(\n",
    "            kernel=self._kernel,\n",
    "            bias=0.0,\n",
    "            weights=support_multipliers,\n",
    "            support_vectors=support_vectors,\n",
    "            support_vector_labels=support_vector_labels\n",
    "        )\n",
    "\n",
    "\n",
    "    def _compute_lagrange_multipliers(self, X, y):\n",
    "        \"\"\"\n",
    "            X: martix of features\n",
    "            y: vector of labels\n",
    "            Need to Solve\n",
    "                min 1/2 x^T P x + q^T x (aplha is x)\n",
    "                s.t.\n",
    "                    Gx <= h (alpha >= 0)\n",
    "                    Ax = b (y^T * alpha = 0)\n",
    "            next step: Get number of samples\n",
    "            next step: Create Kernel matrix by calling _kernel_matrix method\n",
    "            next step: Create create quadratic term P based on Kernel matrix\n",
    "            next step: Create linear term q\n",
    "            next step: Create G, h, A, b\n",
    "            next step: Solve with - cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "            retrun:    Return flatten solution['x']\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        K = self._kernel_matrix(X)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "\n",
    "        q = cvxopt.matrix(-1 * np.ones(n_samples))\n",
    "\n",
    "        G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "\n",
    "        h = cvxopt.matrix(np.zeros(n_samples))\n",
    "\n",
    "        A = cvxopt.matrix(y, (1, n_samples))\n",
    "\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "\n",
    "        # Check this\n",
    "\n",
    "        # -a_i \\leq 0\n",
    "        # G_std = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "        # h_std = cvxopt.matrix(np.zeros(n_samples))\n",
    "\n",
    "        # # a_i \\leq c\n",
    "        # G_slack = cvxopt.matrix(np.diag(np.ones(n_samples)))\n",
    "        # h_slack = cvxopt.matrix(np.ones(n_samples) * self._c)\n",
    "\n",
    "        # G = cvxopt.matrix(np.vstack((G_std, G_slack)))\n",
    "        # h = cvxopt.matrix(np.vstack((h_std, h_slack)))\n",
    "\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        return np.ravel(solution['x'])\n",
    "\n",
    "\n",
    "class SVMPredictor(object):\n",
    "    def __init__(\n",
    "                self,\n",
    "                kernel,\n",
    "                bias,\n",
    "                weights,\n",
    "                support_vectors,\n",
    "                support_vector_labels\n",
    "            ):\n",
    "        \n",
    "        self._kernel = kernel\n",
    "        self._bias = bias\n",
    "        self._weights = weights\n",
    "        self._support_vectors = support_vectors\n",
    "        self._support_vector_labels = support_vector_labels\n",
    "\n",
    "\n",
    "        assert len(support_vectors) == len(support_vector_labels)\n",
    "        assert len(weights) == len(support_vector_labels)\n",
    "\n",
    "\n",
    "        logging.info(\"Bias: %s\", self._bias)\n",
    "        logging.info(\"Weights: %s\", self._weights)\n",
    "        logging.info(\"Support vectors: %s\", self._support_vectors)\n",
    "        logging.info(\"Support vector labels: %s\", self._support_vector_labels)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Computes the SVM prediction on the given features x.\n",
    "        \"\"\"\n",
    "        result = self._bias\n",
    "        for w_i, x_i, y_i in zip(self._weights,\n",
    "                                 self._support_vectors,\n",
    "                                 self._support_vector_labels):\n",
    "            result += w_i * y_i * self._kernel(x_i, x)\n",
    "\n",
    "        return np.sign(result).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def example(num_samples=10, num_features=2, grid_size=20):\n",
    "    \n",
    "    samples = np.matrix(np.random.normal(size=num_samples * num_features)\n",
    "                        .reshape(num_samples, num_features))\n",
    "    \n",
    "    labels = 2 * (samples.sum(axis=1) > 0) - 1.0\n",
    "    \n",
    "    trainer = svm.SVMTrainer(svm.Kernel.gaussian(1))\n",
    "    \n",
    "    predictor = trainer.train(samples, labels)\n",
    "\n",
    "    plot(predictor, samples, labels, grid_size)\n",
    "\n",
    "\n",
    "def plot(predictor, X, y, grid_size):\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    \n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, grid_size),\n",
    "        np.linspace(y_min, y_max, grid_size),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    \n",
    "    flatten = lambda m: np.array(m).reshape(-1,)\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for (i, j) in itertools.product(range(grid_size), range(grid_size)):\n",
    "        point = np.array([xx[i, j], yy[i, j]]).reshape(1, 2)\n",
    "        result.append(predictor.predict(point))\n",
    "\n",
    "    Z = np.array(result).reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(\n",
    "        xx, yy, Z,\n",
    "        cmap=cm.Paired,\n",
    "        levels=[-0.01, 0.01],\n",
    "        extend='both',\n",
    "        alpha=0.8\n",
    "    )\n",
    "    \n",
    "    \n",
    "    plt.scatter(\n",
    "        flatten(X[:, 0]),\n",
    "        flatten(X[:, 1]),\n",
    "        c=flatten(y),\n",
    "        cmap=cm.Paired\n",
    "    )\n",
    "    \n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
